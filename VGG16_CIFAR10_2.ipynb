{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyAQVz2cprtP"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lhJuj6a-Yft"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import SGD, Adam, Nadam, AdamW\n",
        "from tensorflow.keras.optimizers import Optimizer\n",
        "from tensorflow.keras.models import save_model\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o41m6R8-pVd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bffbf21-919f-4f26-c3e1-c43480e2b295"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun May 11 02:16:52 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKQNY2kEjFNc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d643bb46-2839-4087-c095-f237d7a50129"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_5l2lfxjLmj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "def save_all_results(name, history, model, training_time, test_accuracy, save_dir='/content/drive/MyDrive/vgg_results'):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    with open(os.path.join(save_dir, f'{name}_history.json'), 'w') as f:\n",
        "        json.dump(history.history, f)\n",
        "\n",
        "    model.save(os.path.join(save_dir, f'{name}_model.h5'))\n",
        "\n",
        "    summary = {\n",
        "        'training_time': training_time,\n",
        "        'test_accuracy': test_accuracy\n",
        "    }\n",
        "    with open(os.path.join(save_dir, f'{name}_summary.json'), 'w') as f:\n",
        "        json.dump(summary, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2OGbAc0p3Gg"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Qgl5O26pWxY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f4e25e8-1e7f-4e1d-be3d-b687adee991e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)  # One-hot encoding\n",
        "\n",
        "# Split training data into train and validation sets\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
        "\n",
        "# Resize images to (224, 224)\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, (224, 224))\n",
        "    image = tf.keras.applications.vgg16.preprocess_input(image)\n",
        "    return image, label\n",
        "\n",
        "batch_size = 32\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).map(preprocess).shuffle(1000).batch(batch_size)\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((x_val, y_val)).map(preprocess).batch(batch_size)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).map(preprocess).batch(batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErRFo0Hop72L"
      },
      "source": [
        "# Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wj9DTbIoqtL_"
      },
      "outputs": [],
      "source": [
        "def train(optimizer, epochs):\n",
        "\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    base_model.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    start_time = time.time()\n",
        "    history = model.fit(train_ds, epochs=epochs, validation_data=val_ds, verbose=1)\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "\n",
        "    test_loss, test_accuracy = model.evaluate(test_ds, verbose=0)\n",
        "    print(f\"Test accuracy: {test_accuracy}\")\n",
        "\n",
        "    return history, model, training_time, test_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKz7joZVp-tC"
      },
      "source": [
        "# Build Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPbRq-hEpFbQ"
      },
      "outputs": [],
      "source": [
        "class Lion(Optimizer):\n",
        "    def __init__(\n",
        "        self, learning_rate=0.001, beta_1=0.9, beta_2=0.99, weight_decay=1e-4, name=\"lion\", **kwargs):\n",
        "        super().__init__(learning_rate=learning_rate, name=name, **kwargs)\n",
        "        self.beta_1 = beta_1\n",
        "        self.beta_2 = beta_2\n",
        "        self.weight_decay = weight_decay\n",
        "\n",
        "    def build(self, var_list):\n",
        "        if self.built:\n",
        "            return\n",
        "        super().build(var_list)\n",
        "\n",
        "        self._momentums = []\n",
        "        for var in var_list:\n",
        "            self._momentums.append(\n",
        "                self.add_variable_from_reference(\n",
        "                    reference_variable=var, name=\"momentum\"\n",
        "                )\n",
        "            )\n",
        "\n",
        "    def update_step(self, gradient, variable, learning_rate):\n",
        "\n",
        "        lr = tf.cast(learning_rate, variable.dtype)\n",
        "        gradient = tf.cast(gradient, variable.dtype)\n",
        "\n",
        "        beta_1 = tf.cast(self.beta_1, variable.dtype)\n",
        "        beta_2 = tf.cast(self.beta_2, variable.dtype)\n",
        "        weight_decay = tf.cast(self.weight_decay, variable.dtype)\n",
        "\n",
        "        m = self._momentums[self._get_variable_index(variable)]\n",
        "\n",
        "        update = tf.sign(beta_1 * m + (1.0 - beta_1) * gradient)\n",
        "\n",
        "        new_m = beta_2 * m + (1.0 - beta_2) * gradient\n",
        "        self.assign(m, new_m)\n",
        "\n",
        "        final_update = lr * (weight_decay * variable + update)\n",
        "        self.assign_sub(variable, final_update)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSpod47CqD1A"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2IX3NAHpd54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "132a5d22-3af3-46fd-a22d-39b10129bc9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with Adam optimizer...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
            "Epoch 1/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 190ms/step - accuracy: 0.4974 - loss: 2.4166 - val_accuracy: 0.8164 - val_loss: 0.5174\n",
            "Epoch 2/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 191ms/step - accuracy: 0.7356 - loss: 0.7922 - val_accuracy: 0.8142 - val_loss: 0.5210\n",
            "Epoch 3/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 178ms/step - accuracy: 0.7401 - loss: 0.7815 - val_accuracy: 0.8126 - val_loss: 0.5192\n",
            "Epoch 4/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 191ms/step - accuracy: 0.7418 - loss: 0.7721 - val_accuracy: 0.8224 - val_loss: 0.5001\n",
            "Epoch 5/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 189ms/step - accuracy: 0.7374 - loss: 0.7829 - val_accuracy: 0.8200 - val_loss: 0.4989\n",
            "Epoch 6/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 191ms/step - accuracy: 0.7441 - loss: 0.7639 - val_accuracy: 0.8264 - val_loss: 0.4919\n",
            "Epoch 7/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 191ms/step - accuracy: 0.7428 - loss: 0.7777 - val_accuracy: 0.8240 - val_loss: 0.5022\n",
            "Epoch 8/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 189ms/step - accuracy: 0.7417 - loss: 0.7646 - val_accuracy: 0.8222 - val_loss: 0.5043\n",
            "Epoch 9/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 191ms/step - accuracy: 0.7417 - loss: 0.7755 - val_accuracy: 0.8252 - val_loss: 0.4966\n",
            "Epoch 10/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 191ms/step - accuracy: 0.7422 - loss: 0.7734 - val_accuracy: 0.8168 - val_loss: 0.5175\n",
            "Epoch 11/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 191ms/step - accuracy: 0.7432 - loss: 0.7727 - val_accuracy: 0.8116 - val_loss: 0.5251\n",
            "Epoch 12/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 189ms/step - accuracy: 0.7429 - loss: 0.7791 - val_accuracy: 0.8248 - val_loss: 0.5038\n",
            "Epoch 13/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 189ms/step - accuracy: 0.7353 - loss: 0.7978 - val_accuracy: 0.8184 - val_loss: 0.5060\n",
            "Epoch 14/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 179ms/step - accuracy: 0.7434 - loss: 0.7789 - val_accuracy: 0.8222 - val_loss: 0.5052\n",
            "Epoch 15/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 191ms/step - accuracy: 0.7423 - loss: 0.7711 - val_accuracy: 0.8162 - val_loss: 0.5173\n",
            "Epoch 16/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 189ms/step - accuracy: 0.7413 - loss: 0.7741 - val_accuracy: 0.8266 - val_loss: 0.4978\n",
            "Epoch 17/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 191ms/step - accuracy: 0.7428 - loss: 0.7780 - val_accuracy: 0.8146 - val_loss: 0.5236\n",
            "Epoch 18/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 189ms/step - accuracy: 0.7418 - loss: 0.7658 - val_accuracy: 0.8138 - val_loss: 0.5263\n",
            "Epoch 19/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 191ms/step - accuracy: 0.7474 - loss: 0.7724 - val_accuracy: 0.8094 - val_loss: 0.5296\n",
            "Epoch 20/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 179ms/step - accuracy: 0.7393 - loss: 0.7742 - val_accuracy: 0.8112 - val_loss: 0.5285\n",
            "Test accuracy: 0.8134999871253967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with Adam_Amsgrad optimizer...\n",
            "Epoch 1/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 192ms/step - accuracy: 0.5089 - loss: 2.2781 - val_accuracy: 0.8170 - val_loss: 0.5279\n",
            "Epoch 2/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 179ms/step - accuracy: 0.7352 - loss: 0.7992 - val_accuracy: 0.8184 - val_loss: 0.5193\n",
            "Epoch 3/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 191ms/step - accuracy: 0.7410 - loss: 0.7723 - val_accuracy: 0.8230 - val_loss: 0.5110\n",
            "Epoch 4/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 189ms/step - accuracy: 0.7378 - loss: 0.7680 - val_accuracy: 0.8242 - val_loss: 0.4996\n",
            "Epoch 5/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 189ms/step - accuracy: 0.7429 - loss: 0.7630 - val_accuracy: 0.8148 - val_loss: 0.5226\n",
            "Epoch 6/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 189ms/step - accuracy: 0.7428 - loss: 0.7700 - val_accuracy: 0.8268 - val_loss: 0.4950\n",
            "Epoch 7/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 177ms/step - accuracy: 0.7440 - loss: 0.7685 - val_accuracy: 0.8104 - val_loss: 0.5383\n",
            "Epoch 8/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 191ms/step - accuracy: 0.7440 - loss: 0.7592 - val_accuracy: 0.8262 - val_loss: 0.4958\n",
            "Epoch 9/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 189ms/step - accuracy: 0.7431 - loss: 0.7634 - val_accuracy: 0.8202 - val_loss: 0.5179\n",
            "Epoch 10/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 191ms/step - accuracy: 0.7439 - loss: 0.7588 - val_accuracy: 0.8210 - val_loss: 0.4960\n",
            "Epoch 11/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 189ms/step - accuracy: 0.7450 - loss: 0.7583 - val_accuracy: 0.8206 - val_loss: 0.4964\n",
            "Epoch 12/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 180ms/step - accuracy: 0.7429 - loss: 0.7618 - val_accuracy: 0.8116 - val_loss: 0.5278\n",
            "Epoch 13/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 191ms/step - accuracy: 0.7425 - loss: 0.7544 - val_accuracy: 0.8202 - val_loss: 0.5150\n",
            "Epoch 14/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 191ms/step - accuracy: 0.7436 - loss: 0.7696 - val_accuracy: 0.8128 - val_loss: 0.5254\n",
            "Epoch 15/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 191ms/step - accuracy: 0.7437 - loss: 0.7594 - val_accuracy: 0.8222 - val_loss: 0.5032\n",
            "Epoch 16/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 191ms/step - accuracy: 0.7436 - loss: 0.7656 - val_accuracy: 0.8276 - val_loss: 0.4927\n",
            "Epoch 17/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 189ms/step - accuracy: 0.7463 - loss: 0.7622 - val_accuracy: 0.8160 - val_loss: 0.5261\n",
            "Epoch 18/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 189ms/step - accuracy: 0.7467 - loss: 0.7554 - val_accuracy: 0.8220 - val_loss: 0.5085\n",
            "Epoch 19/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 177ms/step - accuracy: 0.7468 - loss: 0.7603 - val_accuracy: 0.8164 - val_loss: 0.5210\n",
            "Epoch 20/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 191ms/step - accuracy: 0.7462 - loss: 0.7577 - val_accuracy: 0.8144 - val_loss: 0.5377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.8087000250816345\n"
          ]
        }
      ],
      "source": [
        "optimizers = {\n",
        "#    'SGD': SGD(learning_rate=0.001, momentum=0.9),\n",
        "#    'SGD_Nesterov': SGD(learning_rate=0.001, momentum=0.9, nesterov=True),\n",
        "    'Adam': Adam(learning_rate=0.001),\n",
        "    'Adam_Amsgrad': Adam(learning_rate=0.001, amsgrad=True),\n",
        "#    'AdamW': AdamW(learning_rate=0.001, weight_decay=1e-4),\n",
        "#    'Nadam': Nadam(learning_rate=0.001),\n",
        "#    'Lion': Lion(learning_rate=1e-4)\n",
        "}\n",
        "\n",
        "histories = {}\n",
        "training_times = {}\n",
        "models = {}\n",
        "test_accuracies = {}\n",
        "\n",
        "for name, optimizer in optimizers.items():\n",
        "    print(f\"Training with {name} optimizer...\")\n",
        "\n",
        "    histories[name], models[name], training_times[name], test_accuracies[name] = train(optimizer, 20)\n",
        "\n",
        "    save_all_results(name, histories[name], models[name], training_times[name], test_accuracies[name])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuClass": "premium",
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}